============================= test session starts ==============================
platform darwin -- Python 3.10.6, pytest-7.3.1, pluggy-1.0.0
rootdir: /Users/sahammond/rubricapp/BackEndFlask
plugins: anyio-3.6.1, cov-3.0.0
collected 33 items

Functions/test_files/test_genericImport.py FFFFFFFFFF                    [ 30%]
Functions/test_files/test_randAssignTeams.py FFFFF                       [ 45%]
Functions/test_files/test_teamBulkUpload.py .FFFFFFFF                    [ 72%]
Functions/test_files/test_teamImport.py FFFFFFFFF                        [100%]

=================================== FAILURES ===================================
_____________________ test_should_fail_with_file_not_found _____________________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/NonExistentFile.csv'
owner_id = 185, course_id = 56

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/NonExistentFile.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_file_not_found(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
>               generic_csv_to_db(
                    retrieve_file_path("NonExistentFile.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/NonExistentFile.csv'
owner_id = 185, course_id = 56

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/NonExistentFile.csv'
owner_id = 185, course_id = 56

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x10f85a320>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10f87b970>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 185}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10f87b910>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 185}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10f87b970>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10f87b910>
query = 'DELETE FROM `User` WHERE `User`.user_id = 185'
args = {'user_id_1': 185}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10f87b910>
q = 'DELETE FROM `User` WHERE `User`.user_id = 185'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10f7fc9a0>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 185', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10f7fc9a0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10f87b4f0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10f7fc9a0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10f87a920>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_file_not_found(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
                generic_csv_to_db(
                    retrieve_file_path("NonExistentFile.csv"),
                    result["user_id"],
                    result["course_id"]
                )
            except Exception as e:
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 185}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:13,699 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 185}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 185}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
____________________ test_should_fail_with_wrong_extension _____________________

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_wrong_extension(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
>               generic_csv_to_db(
                    retrieve_file_path("wrongExtension.txt"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/wrongExtension.txt'
owner_id = 186, course_id = 57

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/wrongExtension.txt'
owner_id = 186, course_id = 57

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
>               raise WrongExtension
E               Functions.customExceptions.WrongExtension: Raised when the submitted file is not a csv or xlsx

Functions/genericImport.py:148: WrongExtension

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x12d72a260>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d729db0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 186}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d72ae30>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 186}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d729db0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d72ae30>
query = 'DELETE FROM `User` WHERE `User`.user_id = 186'
args = {'user_id_1': 186}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d72ae30>
q = 'DELETE FROM `User` WHERE `User`.user_id = 186'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d72b880>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 186', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d72b880>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d72afe0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d72b880>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d72b5e0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_wrong_extension(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
                generic_csv_to_db(
                    retrieve_file_path("wrongExtension.txt"),
                    result["user_id"],
                    result["course_id"]
                )
            except Exception as e:
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 186}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:14,115 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 186}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 186}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
___________________ test_should_fail_with_not_enough_columns ___________________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/notEnoughColumns.csv'
owner_id = 187, course_id = 58

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/notEnoughColumns.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_not_enough_columns(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
>               generic_csv_to_db(
                    retrieve_file_path("notEnoughColumns.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/notEnoughColumns.csv'
owner_id = 187, course_id = 58

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/notEnoughColumns.csv'
owner_id = 187, course_id = 58

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x12d481e40>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d481c90>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 187}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d482440>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 187}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d481c90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d482440>
query = 'DELETE FROM `User` WHERE `User`.user_id = 187'
args = {'user_id_1': 187}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d482440>
q = 'DELETE FROM `User` WHERE `User`.user_id = 187'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d482bf0>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 187', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d482bf0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d4826e0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d482bf0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d482ad0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_not_enough_columns(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
                generic_csv_to_db(
                    retrieve_file_path("notEnoughColumns.csv"),
                    result["user_id"],
                    result["course_id"]
                )
            except Exception as e:
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 187}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:14,414 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 187}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 187}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
_______________ test_should_fail_with_misformatted_student_email _______________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/invalidStudentEmail.csv'
owner_id = 188, course_id = 59

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/invalidStudentEmail.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_misformatted_student_email(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
>               generic_csv_to_db(
                    retrieve_file_path("invalidStudentEmail.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/invalidStudentEmail.csv'
owner_id = 188, course_id = 59

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/invalidStudentEmail.csv'
owner_id = 188, course_id = 59

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x12d202080>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d202fe0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 188}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d2036a0>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 188}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d202fe0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d2036a0>
query = 'DELETE FROM `User` WHERE `User`.user_id = 188'
args = {'user_id_1': 188}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d2036a0>
q = 'DELETE FROM `User` WHERE `User`.user_id = 188'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d203d90>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 188', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d203d90>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d2024a0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d203d90>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d202d40>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_misformatted_student_email(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
                generic_csv_to_db(
                    retrieve_file_path("invalidStudentEmail.csv"),
                    result["user_id"],
                    result["course_id"]
                )
            except Exception as e:
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 188}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:14,762 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 188}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 188}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
__________________ test_valid_student_with_no_lms_id_in_table __________________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneStudentNoLMSID.csv'
owner_id = 189, course_id = 60

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneStudentNoLMSID.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_valid_student_with_no_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
>               message = generic_csv_to_db(
                    retrieve_file_path("oneStudentNoLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneStudentNoLMSID.csv'
owner_id = 189, course_id = 60

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneStudentNoLMSID.csv'
owner_id = 189, course_id = 60

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x12d77ff40>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d77ff10>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 189}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d77ff70>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 189}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d77ff10>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d77ff70>
query = 'DELETE FROM `User` WHERE `User`.user_id = 189'
args = {'user_id_1': 189}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d77ff70>
q = 'DELETE FROM `User` WHERE `User`.user_id = 189'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d77c7f0>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 189', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d77c7f0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d77d090>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d77c7f0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d77d270>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_valid_student_with_no_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
                message = generic_csv_to_db(
                    retrieve_file_path("oneStudentNoLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )
                assert message is None, message # generic_csv_to_db() returns none when successful
    
                user = get_user_by_email("teststudent1@gmail.com")
    
                error_message = "generic_csv_to_db() did not correctly create the valid test student"
                assert user is not None, error_message
    
                user_id = get_user_user_id_by_email("teststudent1@gmail.com")
                user_courses = get_user_courses_by_user_id(user_id)
    
                error_message = "generic_csv_to_db() did not correctly enroll the valid test student in the test course"
                assert user_courses.__len__() == 1, error_message
    
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_course(result)
            except:
                delete_all_users_user_courses(result["course_id"])
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 189}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:15,068 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 189}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 189}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
___________________ test_valid_student_with_lms_id_in_table ____________________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneStudentWithLMSID.csv'
owner_id = 190, course_id = 61

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneStudentWithLMSID.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_valid_student_with_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
>               message = generic_csv_to_db(
                    retrieve_file_path("oneStudentWithLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneStudentWithLMSID.csv'
owner_id = 190, course_id = 61

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneStudentWithLMSID.csv'
owner_id = 190, course_id = 61

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x12ce75c60>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12ce74f70>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 190}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12ce745b0>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 190}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12ce74f70>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12ce745b0>
query = 'DELETE FROM `User` WHERE `User`.user_id = 190'
args = {'user_id_1': 190}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12ce745b0>
q = 'DELETE FROM `User` WHERE `User`.user_id = 190'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12ce74880>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 190', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12ce74880>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12ce750c0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12ce74880>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12ce75270>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_valid_student_with_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(False)
                message = generic_csv_to_db(
                    retrieve_file_path("oneStudentWithLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )
    
                assert message is None, message # generic_csv_to_db() returns none when successful
    
                user = get_user_by_email("teststudent1@gmail.com")
    
                error_message = "generic_csv_to_db() did not correctly create the valid test student"
                assert user is not None, error_message
    
                error_message = "upload failed to assign lms_id attribute to student when expected."
                assert user.lms_id is not None, error_message
    
                user_id = get_user_user_id_by_email("teststudent1@gmail.com")
                user_courses = get_user_courses_by_user_id(user_id)
    
                error_message = "generic_csv_to_db() did not correctly enroll the valid test student in the test course"
                assert user_courses.__len__() == 1, error_message
    
                delete_all_users_user_courses(result["course_id"])
                error_message = "delete_one_admin_course() encountered an unexpected error!"
                delete_one_admin_course(result)
    
            except:
                delete_all_users_user_courses(result["course_id"])
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 190}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:15,414 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 190}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 190}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
____________________ test_valid_ta_with_no_lms_id_in_table _____________________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneTANoLMSID.csv'
owner_id = 191, course_id = 62

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneTANoLMSID.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_valid_ta_with_no_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(True)
>               message = generic_csv_to_db(
                    retrieve_file_path("oneTANoLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneTANoLMSID.csv'
owner_id = 191, course_id = 62

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneTANoLMSID.csv'
owner_id = 191, course_id = 62

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x10fc15cc0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc16b60>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 191}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10fc166e0>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 191}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc16b60>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fc166e0>
query = 'DELETE FROM `User` WHERE `User`.user_id = 191'
args = {'user_id_1': 191}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fc166e0>
q = 'DELETE FROM `User` WHERE `User`.user_id = 191'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc17850>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 191', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc17850>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10fc167a0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc17850>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10fc165c0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_valid_ta_with_no_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(True)
                message = generic_csv_to_db(
                    retrieve_file_path("oneTANoLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )
                assert message is None, message # generic_csv_to_db() returns none when successful
                user = get_user_by_email("testTA1@gmail.com")
    
                error_message = "generic_csv_to_db() did not correctly create the valid test TA"
                assert user is not None, error_message
    
                user_id = get_user_user_id_by_email("testTA1@gmail.com")
                user_courses = get_user_courses_by_user_id(user_id)
    
                error_message = "generic_csv_to_db() did not correctly enroll the valid test TA in the test course"
                assert user_courses.__len__() == 1, error_message
    
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_course(result)
            except:
                delete_all_users_user_courses(result["course_id"])
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:175: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 191}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:15,719 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 191}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 191}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
______________________ test_valid_ta_with_lms_id_in_table ______________________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneTAWithLMSID.csv'
owner_id = 192, course_id = 63

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneTAWithLMSID.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_valid_ta_with_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(True)
>               message = generic_csv_to_db(
                    retrieve_file_path("oneTAWithLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:183: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneTAWithLMSID.csv'
owner_id = 192, course_id = 63

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/oneTAWithLMSID.csv'
owner_id = 192, course_id = 63

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x12d5a9b40>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d5a8e20>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 192}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d5a90f0>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 192}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d5a8e20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d5a90f0>
query = 'DELETE FROM `User` WHERE `User`.user_id = 192'
args = {'user_id_1': 192}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d5a90f0>
q = 'DELETE FROM `User` WHERE `User`.user_id = 192'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d5a8790>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 192', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d5a8790>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d5a9060>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d5a8790>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d5a9240>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_valid_ta_with_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(True)
                message = generic_csv_to_db(
                    retrieve_file_path("oneTAWithLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )
                assert message is None, message # generic_csv_to_db() returns none when successful
    
                user = get_user_by_email("testTA1@gmail.com")
    
                error_message = "generic_csv_to_db() did not correctly create the valid test TA"
                assert user is not None, error_message
    
                error_message = "upload failed to assign lms_id attribute to TA when expected."
                assert user.lms_id is not None, error_message
    
                user_id = get_user_user_id_by_email("testTA1@gmail.com")
                user_courses = get_user_courses_by_user_id(user_id)
    
                error_message = "generic_csv_to_db() did not correctly enroll the valid test TA in the test course"
                assert user_courses.__len__() == 1, error_message
    
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_course(result)
            except:
                delete_all_users_user_courses(result["course_id"])
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 192}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:16,055 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 192}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 192}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
______________ test_valid_student_and_ta_with_no_lms_id_in_table _______________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/StudentAndTANoLMSID.csv'
owner_id = 193, course_id = 64

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/StudentAndTANoLMSID.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_valid_student_and_ta_with_no_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(True)
>               message = generic_csv_to_db(
                    retrieve_file_path("StudentAndTANoLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/StudentAndTANoLMSID.csv'
owner_id = 193, course_id = 64

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/StudentAndTANoLMSID.csv'
owner_id = 193, course_id = 64

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x12d2b18d0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2b2290>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 193}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d2b2380>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 193}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2b2290>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d2b2380>
query = 'DELETE FROM `User` WHERE `User`.user_id = 193'
args = {'user_id_1': 193}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d2b2380>
q = 'DELETE FROM `User` WHERE `User`.user_id = 193'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2b28f0>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 193', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2b28f0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d2b21d0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2b28f0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d2b2020>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_valid_student_and_ta_with_no_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(True)
                message = generic_csv_to_db(
                    retrieve_file_path("StudentAndTANoLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )
                assert message is None, message # generic_csv_to_db() returns none when successful
                user = get_user_by_email("testTA1@gmail.com")
    
                error_message = "generic_csv_to_db() did not correctly create the valid test TA"
                assert user is not None, error_message
    
                user = get_user_by_email("teststudent1@gmail.com")
    
                error_message = "generic_csv_to_db() did not correctly create the valid test student"
                assert user is not None, error_message
    
                user_id = get_user_user_id_by_email("testTA1@gmail.com")
                user_courses = get_user_courses_by_user_id(user_id)
    
                error_message = "generic_csv_to_db() did not correctly enroll the valid test TA in the test course"
                assert user_courses.__len__() == 1, error_message
    
                user_id = get_user_user_id_by_email("teststudent1@gmail.com")
                user_courses = get_user_courses_by_user_id(user_id)
    
                error_message = "generic_csv_to_db() did not correctly enroll the valid test student in the test course"
                assert user_courses.__len__() == 1, error_message
    
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_course(result)
            except:
                delete_all_users_user_courses(result["course_id"])
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 193}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:16,354 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 193}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 193}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
________ test_valid_students_and_tas_with__and_without_lms_id_in_table _________

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/StudentAndTAWithLMSID.csv'
owner_id = 194, course_id = 65

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
>               student_csv = open(user_file, mode='r', encoding='utf-8-sig')
E               FileNotFoundError: [Errno 2] No such file or directory: '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/StudentAndTAWithLMSID.csv'

Functions/genericImport.py:157: FileNotFoundError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_valid_students_and_tas_with__and_without_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(True)
>               message = generic_csv_to_db(
                    retrieve_file_path("StudentAndTAWithLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )

Functions/test_files/test_genericImport.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/StudentAndTAWithLMSID.csv'
owner_id = 194, course_id = 65

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
                raise FileNotFound
    
            # Renamed `reader` -> `roster`.
            roster: list[list[str]] = list(itertools.tee(csv.reader(student_csv))[0])
    
            if not roster:
                raise EmptyFile()
    
            # For keeping students in a "queue" as we are parsing
            # the file. During parsing, we add the relevant information
            # to this list (first_name, last_name, email, role_id, lms_id).
            students: list[tuple] = []
    
            # Track duplicate checks
            seen_emails: dict[str, int] = {}
            seen_lms_ids: dict[str, int] = {}
            valid_roles = ["Student", "TA", "Instructor"]
    
            for row in range(0, len(roster)):
                person_attribs: list[str] = roster[row]
    
                # Skip empty rows
                if len(person_attribs) == 0:
                    continue
    
                MIN_PERSON_ATTRIBS_COUNT: int = 3  # Checking for 3 for: FN LN, email, role
    
                MAX_PERSON_ATTRIBS_COUNT: int = 4  # Checking for 4 for: FN LN, email, role, (optional) LMS ID
    
                if len(person_attribs) < MIN_PERSON_ATTRIBS_COUNT:
                    raise NotEnoughColumns(row + 1, MIN_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                if len(person_attribs) > MAX_PERSON_ATTRIBS_COUNT:
                    raise TooManyColumns(row + 1, MAX_PERSON_ATTRIBS_COUNT, len(person_attribs))
    
                name: str = person_attribs[0].strip()  # FN,LN
    
                # Validate name format
                if ',' not in name:
                    raise InvalidNameFormat(row + 1, name)
    
                last_name: str = name.split(',')[0].strip()
                first_name: str = name.split(',')[1].strip()
    
                if not last_name or not first_name:
                    raise InvalidNameFormat(row + 1, name)
    
                email: str = person_attribs[1].strip()
    
                # Check for duplicate emails
                if email in seen_emails:
                    raise DuplicateEmail(email, [seen_emails[email], row + 1])
                seen_emails[email] = row + 1
    
                role: str = person_attribs[2].strip()
    
                # Validate role before conversion
                if role not in valid_roles:
                    raise InvalidRole(row + 1, role, valid_roles)
    
                lms_id: int|None = None
    
                role = helper_str_to_int_role(role)
                role = get_role(role)
                role_id = role.role_id
    
                # If the len of person_attribs == 4, then the LMS ID is present.
                if len(person_attribs) == 4:
                    lms_id = person_attribs[3].strip()
                    if lms_id:  # Only validate if not empty
                        if not lms_id.isdigit():
                            raise InvalidLMSID(row + 1, lms_id)
                        if lms_id in seen_lms_ids:
                            raise DuplicateLMSID(lms_id, [seen_lms_ids[lms_id], row + 1])
                        seen_lms_ids[lms_id] = row + 1
    
                if not helper_verify_email_syntax(email):
                    raise InvalidEmail(row + 1, email)
    
                students.append((first_name, last_name, email, role_id, lms_id))
    
            for first_name, last_name, email, role_id, lms_id in students:
                __add_user(owner_id, course_id, first_name, last_name, email, role_id, lms_id)
    
            student_csv.close()
    
            delete_xlsx(user_file, is_xlsx)
    
            return None
    
        except Exception as e:
            if student_csv is not None:
                student_csv.close()
    
            if is_xlsx is not None:
                delete_xlsx(user_file, is_xlsx)
    
>           raise e

Functions/genericImport.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_file = '/Users/sahammond/rubricapp/BackEndFlask/Functions/sample_files/StudentAndTAWithLMSID.csv'
owner_id = 194, course_id = 65

    def generic_csv_to_db(user_file: str, owner_id: int, course_id: int) -> None|str:
        """
        Description:
        Takes a csv file and creates users of any type (student, TA, etc.)
        and adds them to the database.
    
        Parameters:
        user_file: str: The path to the csv file.
        owner_id: int:  The user_id of the owner of the course.
        course_id: int: The course_id of the course to add the users to.
    
        Returns:
        None: On success.
        """
        student_csv: None|object = None
    
        is_xlsx: bool|None = None
    
        try:
            if not user_file.endswith('.csv') and not user_file.endswith('.xlsx'):
                raise WrongExtension
    
            # Determine if file is .xlsx.
            is_xlsx = user_file.endswith('.xlsx')
    
            if is_xlsx:
                user_file = xlsx_to_csv(user_file)
    
            try:
                student_csv = open(user_file, mode='r', encoding='utf-8-sig')
    
            except FileNotFoundError:
                #delete_xlsx(user_file, is_xlsx)
    
>               raise FileNotFound
E               Functions.customExceptions.FileNotFound: File not found or does not exist!

Functions/genericImport.py:162: FileNotFound

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x12d01e2c0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f700>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f87afe0>
parameters = [{'user_id_1': 194}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d01f220>
statement = 'DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s'
parameters = {'user_id_1': 194}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f700>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d01f220>
query = 'DELETE FROM `User` WHERE `User`.user_id = 194'
args = {'user_id_1': 194}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d01f220>
q = 'DELETE FROM `User` WHERE `User`.user_id = 194'

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01eb00>
sql = b'DELETE FROM `User` WHERE `User`.user_id = 194', unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01eb00>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d01f310>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01eb00>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d01f280>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_valid_students_and_tas_with__and_without_lms_id_in_table(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_course(True)
                message = generic_csv_to_db(
                    retrieve_file_path("StudentAndTAWithLMSID.csv"),
                    result["user_id"],
                    result["course_id"]
                )
                assert message is None, message # generic_csv_to_db() returns none when successful
                user = get_user_by_email("testTA1@gmail.com")
    
                error_message = "generic_csv_to_db() did not correctly create the valid test TA"
                assert user is not None, error_message
    
                error_message = "upload failed to assign lms_id attribute to TA when expected."
                assert user.lms_id is not None, error_message
    
                user = get_user_by_email("teststudent1@gmail.com")
    
                error_message = "generic_csv_to_db() did not correctly create the valid test student"
                assert user is not None, error_message
    
                error_message = "upload failed to assign lms_id attribute to student when expected."
                assert user.lms_id is not None, error_message
    
                user_id = get_user_user_id_by_email("testTA1@gmail.com")
                user_courses = get_user_courses_by_user_id(user_id)
    
                error_message = "generic_csv_to_db() did not correctly enroll the valid test TA in the test course"
                assert user_courses.__len__() == 1, error_message
    
                user_id = get_user_user_id_by_email("teststudent1@gmail.com")
                user_courses = get_user_courses_by_user_id(user_id)
    
                error_message = "generic_csv_to_db() did not correctly enroll the valid test student in the test course"
                assert user_courses.__len__() == 1, error_message
    
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_course(result)
            except:
                delete_all_users_user_courses(result["course_id"])
>               delete_one_admin_course(result)

Functions/test_files/test_genericImport.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
Functions/test_files/PopulationFunctions.py:80: in delete_one_admin_course
    user = delete_user(result["user_id"])
models/utility.py:118: in wrapper
    raise e
models/utility.py:114: in wrapper
    return f(*args, *kwargs)
models/user.py:373: in delete_user
    User.query.filter_by(user_id=user_id).delete()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/query.py:3182: in delete
    self.session.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2232: in execute
    return self._execute_internal(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2127: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py:1916: in orm_execute_statement
    return super().orm_execute_statement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/context.py:292: in orm_execute_statement
    result = conn.execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: in execute
    return meth(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: in _execute_on_connection
    return connection._execute_clauseelement(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: in _execute_clauseelement
    ret = self._execute_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_single_context(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: in _exec_single_context
    self._handle_dbapi_exception(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: in _exec_single_context
    self.dialect.do_execute(
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: in do_execute
    cursor.execute(statement, parameters)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: in execute
    result = self._query(query)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: in _query
    conn.query(q)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: in _read_query_result
    result.read()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: in read
    first_packet = self.connection._read_packet()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: in _read_packet
    packet.raise_for_error()
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: in raise_for_error
    err.raise_mysql_exception(self._data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b'\xff\xab\x05#23000Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)'

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
E       [SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
E       [parameters: {'user_id_1': 194}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:16,692 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 194}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1451, 'Cannot delete or update a parent row: a foreign key constraint fails (`rubricapp`.`course`, CONSTRAINT `course_ibfk_1` FOREIGN KEY (`admin_id`) REFERENCES `user` (`user_id`) ON DELETE RESTRICT)')
[SQL: DELETE FROM `User` WHERE `User`.user_id = %(user_id_1)s]
[parameters: {'user_id_1': 194}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
___________________________ test_one_ta_ten_students ___________________________

self = <sqlalchemy.engine.base.Connection object at 0x10ffc1630>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10ffc27d0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10ffc2500>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10ffc27d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10ffc2500>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:16.989198')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10ffc2500>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:16.989198')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10ffc0790>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:16.989198')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10ffc0790>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10ffc15d0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10ffc0790>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10ffc3fd0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_one_ta_ten_students(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_randAssignTeams.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 4563144176)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10ffc0eb0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10f956a40>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10f956a40>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10f956a40>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10f956a40>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10f956a40>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10f956a40>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10ffc0eb0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10ffc0eb0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x10ffc07c0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10ffc0eb0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10ffc0c10>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10ffc0c10>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12ca23530>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10ffc0c10>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10ffc0c10>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12ca23220>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10ffc1630>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x10ffc1630>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10ffc1630>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10ffc1630>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x10fa47ee0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10ffc27d0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10ffc1630>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10ffc27d0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10ffc1630>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x10ffc2500>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10ffc27d0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10ffc1630>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10ffc27d0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10ffc2500>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10ffc27d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10ffc2500>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:16.989198')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10ffc2500>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:16.989198')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10ffc0790>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:16.989198')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10ffc0790>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10ffc15d0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10ffc0790>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10ffc3fd0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$5Bt7ldMLHW3xNbnI$69df7b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 16, 989198)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_one_ta_ten_students(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                students = create_users(result["course_id"], result["admin_id"], 10)
    
                random = RandomAssignTeams(
                    result["observer_id"],
                    result["course_id"]
                )
                random_assign_teams_created = get_team_by_course_id(result["course_id"])
    
                error_message = "RandomAssignTeams() did not correctly create and assign 3 teams"
                assert random_assign_teams_created.__len__() == 3, error_message
    
                total_team_users = 0
                teams = []
                for team in random_assign_teams_created:
                    teams.append(team)
                    team_users = get_team_users_by_team_id(team.team_id)
    
                    error_message = "RandomAssignTeams() did not correctly assign a max size per team of 4 students"
                    assert team_users.__len__() <= 4, error_message
    
                    total_team_users += team_users.__len__()
    
                error_message = "RandomAssignTeams() did not correctly assign all 10 test students to 3 teams!"
                assert total_team_users == 10, error_message
    
                error_message = "RandomAssignTeams() did not correctly assing the test ta to all the 3 teams!"
                assert user_is_only_assigned_to_teams(result["observer_id"], teams), error_message
    
                delete_all_teams_team_members(result["course_id"])
                delete_users(students)
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_randAssignTeams.py:52: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:16,995 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$5Bt7ldMLHW3xNbnI$69df7b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 16, 989198)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$5Bt7ldMLHW3xNbnI$69df7b587df49ce3b2112859b158502c6f48d845d36796b4f88e63223363d2c3', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 16, 989198)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
___________________________ test_no_ta_ten_students ____________________________

self = <sqlalchemy.engine.base.Connection object at 0x12d0bfb50>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d0be830>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d0be590>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d0be830>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d0be590>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.361436')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d0be590>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.361436')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d0bda80>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.361436')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d0bda80>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d0bfaf0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d0bda80>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d0bfc40>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_no_ta_ten_students(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course(False)

Functions/test_files/test_randAssignTeams.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = False, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5050720000)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d0bdfc0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d116a00>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d116a00>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d116a00>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d116a00>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d116a00>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d116a00>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d0bdfc0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d0bdfc0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12d0bd900>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d0bdfc0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d0bde10>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d0bde10>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d807a00>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d0bde10>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d0bde10>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d807840>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d0bfb50>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12d0bfb50>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d0bfb50>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d0bfb50>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12cac5900>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d0be830>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d0bfb50>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d0be830>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d0bfb50>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12d0be590>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d0be830>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d0bfb50>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d0be830>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d0be590>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d0be830>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d0be590>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.361436')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d0be590>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.361436')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d0bda80>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.361436')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d0bda80>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d0bfaf0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d0bda80>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d0bfc40>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$r04H6cNHjZifgUUr$27dbb78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 17, 361436)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_no_ta_ten_students(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course(False)
                students = create_users(result["course_id"], result["admin_id"], 10)
    
                random = RandomAssignTeams(
                    result["observer_id"],
                    result["course_id"]
                )
    
                random_assign_teams_created = get_team_by_course_id(result["course_id"])
    
                error_message = "RandomAssignTeams() did not correctly create and assign 3 teams"
                assert random_assign_teams_created.__len__() == 3, error_message
    
                total_team_users = 0
                teams = []
                for team in random_assign_teams_created:
                    teams.append(team)
                    team_users = get_team_users_by_team_id(team.team_id)
    
                    error_message = "RandomAssignTeams() did not correctly assign a max size per team of 4 students"
                    assert team_users.__len__() <= 4, error_message
    
                    total_team_users += team_users.__len__()
    
                error_message = "RandomAssignTeams() did not correctly assign all 10 test students to 3 teams!"
                assert total_team_users == 10, error_message
    
                error_message = "RandomAssignTeams() did not correctly assing the test ta to all the 3 teams!"
                assert user_is_only_assigned_to_teams(result["observer_id"], teams), error_message
    
                delete_all_teams_team_members(result["course_id"])
                delete_users(students)
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_ta_student_course(result, False)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_randAssignTeams.py:103: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:17,364 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$r04H6cNHjZifgUUr$27dbb78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 17, 361436)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$r04H6cNHjZifgUUr$27dbb78a6d061f497136391542338835a37efac0b4e3e6b87a5860725637b387', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 17, 361436)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
__________________________ test_ten_tas_ten_students ___________________________

self = <sqlalchemy.engine.base.Connection object at 0x12c894ee0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c8962c0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12c896470>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c8962c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c896470>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...0e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.687451')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c896470>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...0e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.687451')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c8953f0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...0e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.687451')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c8953f0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12c894f40>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c8953f0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12c894be0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_ten_tas_ten_students(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_randAssignTeams.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5042161792)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c894850>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cd441c0>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cd441c0>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cd441c0>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cd441c0>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cd441c0>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cd441c0>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c894850>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c894850>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12c895270>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c894850>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c895630>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c895630>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12cdfb530>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c895630>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c895630>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12cdfb840>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c894ee0>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12c894ee0>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c894ee0>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c894ee0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d12e620>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c8962c0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c894ee0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c8962c0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c894ee0>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12c896470>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c8962c0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c894ee0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c8962c0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12c896470>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c8962c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c896470>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...0e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.687451')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c896470>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...0e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.687451')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c8953f0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...0e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:17.687451')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c8953f0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12c894f40>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c8953f0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12c894be0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$AejzzSplROOvUYwl$747b90e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 17, 687451)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_ten_tas_ten_students(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                tas = create_users(result["course_id"], result["admin_id"], 10, 4)
                students = create_users(result["course_id"], result["admin_id"], 10)
    
                random = RandomAssignTeams(
                    result["observer_id"],
                    result["course_id"],
                    1
                )
    
                user_courses = get_user_courses_by_course_id(result["course_id"])
                all_tas = filter_users_by_role(user_courses, 4)
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "RandomAssignTeams() did not correctly create and assign 10 teams"
                assert teams.__len__() == 10, error_message
    
                total_team_users = 0
                for team in teams:
                    error_message = "RandomAssignTeams() did not correctly assign a ta to a team!"
                    assert ta_is_assigned_to_team(all_tas, team), error_message
    
                    team_users = get_team_users_by_team_id(team.team_id)
    
                    error_message = "RandomAssignTeams() did not correctly assign a max size per team of 1 student"
                    assert team_users.__len__() == 1, error_message
                    total_team_users += team_users.__len__()
    
                error_message = "RandomAssignTeams() did not correctly assign all 10 test students to 10 teams!"
                assert total_team_users == 10, error_message
    
                delete_all_teams_team_members(result["course_id"])
                delete_users(tas)
                delete_users(students)
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_randAssignTeams.py:156: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:17,691 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$AejzzSplROOvUYwl$747b90e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 17, 687451)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$AejzzSplROOvUYwl$747b90e329009cac2e283ffe8eb5f0094c522ebbfbee829ee4b712ccee631fd0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 17, 687451)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
____________________ test_TA_true_but_no_TAs_recorded_error ____________________

self = <sqlalchemy.engine.base.Connection object at 0x10fb94c10>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fb973a0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10fb97430>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fb973a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fb97430>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.046466')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fb97430>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.046466')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fb95930>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.046466')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fb95930>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10fb94c40>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fb95930>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10fb94760>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_TA_true_but_no_TAs_recorded_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course(True, True)

Functions/test_files/test_randAssignTeams.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = True, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 4558771856)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fb956c0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ff66c00>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ff66c00>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ff66c00>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ff66c00>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ff66c00>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ff66c00>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fb956c0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fb956c0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x10fb95660>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fb956c0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fb956f0>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fb956f0>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12cad4dd0>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fb956f0>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fb956f0>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12cad4970>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fb94c10>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x10fb94c10>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fb94c10>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fb94c10>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d862ce0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fb973a0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fb94c10>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fb973a0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fb94c10>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x10fb97430>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fb973a0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fb94c10>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fb973a0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10fb97430>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fb973a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fb97430>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.046466')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fb97430>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.046466')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fb95930>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.046466')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fb95930>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10fb94c40>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fb95930>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10fb94760>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$qMYSXK3WOllU6dKT$04202c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 46466)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_TA_true_but_no_TAs_recorded_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course(True, True)
                try:
                    random = RandomAssignTeams(
                        result["observer_id"],
                        result["course_id"]
                    )
                    assert False, "Should not reach this line"
    
                except Exception as e:
                    assert isinstance(e, NoTAsListed), f"Expected NoTAsListed, got {e}"
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "RandomAssignTeams() should not have made and enrolled any test teams in the test course!"
                assert teams.__len__() == 0, error_message
    
                delete_all_teams_team_members(result["course_id"])
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_randAssignTeams.py:191: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:18,050 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$qMYSXK3WOllU6dKT$04202c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 46466)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$qMYSXK3WOllU6dKT$04202c06c1dcf7209c4026a0a2628d5ab13db19a579534440b347446e90424e9', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 46466)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
_______________________ test_no_students_in_course_error _______________________

self = <sqlalchemy.engine.base.Connection object at 0x10fc50760>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc50430>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10fc50550>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc50430>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fc50550>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.382276')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fc50550>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.382276')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc51360>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.382276')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc51360>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10fc503d0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc51360>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10fc504f0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_no_students_in_course_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course(True, False, True)

Functions/test_files/test_randAssignTeams.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = True

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 4559539984)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fc510f0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c8a0a00>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c8a0a00>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c8a0a00>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c8a0a00>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c8a0a00>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c8a0a00>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fc510f0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fc510f0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x10fc51600>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fc510f0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fc51180>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fc51180>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d89f8b0>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fc51180>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fc51180>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d89f920>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fc50760>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x10fc50760>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fc50760>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fc50760>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12cafb280>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc50430>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fc50760>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc50430>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fc50760>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x10fc50550>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc50430>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fc50760>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc50430>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10fc50550>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fc50430>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fc50550>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.382276')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fc50550>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.382276')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc51360>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.382276')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc51360>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10fc503d0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fc51360>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10fc504f0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$IJF3ZCp4gUvwcFLd$971fb40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 382276)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_no_students_in_course_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course(True, False, True)
    
                try:
                    random = RandomAssignTeams(
                        result["observer_id"],
                        result["course_id"]
                    )
                    assert False, "Should not reach this line"
    
                except Exception as e:
                    assert isinstance(e, NoStudentsInCourse), f"Expected NoStudentsInCourse but got {e}"
    
                delete_all_teams_team_members(result["course_id"])
                delete_all_users_user_courses(result["course_id"])
                delete_one_admin_ta_student_course(result)
    
            except:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_randAssignTeams.py:220: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:18,385 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$IJF3ZCp4gUvwcFLd$971fb40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 382276)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$IJF3ZCp4gUvwcFLd$971fb40762a31fe1d37a6dfbaea1c5249af7307f6366c292c0a07b51a8d77365', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 382276)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
_________________ test_should_fail_with_non_existant_ta_email __________________

self = <sqlalchemy.engine.base.Connection object at 0x12d01c5b0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f0d0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d01e5c0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f0d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d01e5c0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.783365')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d01e5c0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.783365')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01ecb0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.783365')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01ecb0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d01cf70>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01ecb0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d01d960>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_non_existant_ta_email(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamBulkUpload.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5050068528)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d01c970>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d6a5800>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d6a5800>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d6a5800>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d6a5800>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d6a5800>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d6a5800>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d01c970>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d01c970>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12d01faf0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d01c970>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d01edd0>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d01edd0>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d84fb50>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d01edd0>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d01edd0>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d84e500>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d01c5b0>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12d01c5b0>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d01c5b0>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d01c5b0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12cae6d40>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f0d0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d01c5b0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f0d0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d01c5b0>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12d01e5c0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f0d0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d01c5b0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f0d0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d01e5c0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d01f0d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d01e5c0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.783365')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d01e5c0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.783365')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01ecb0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:18.783365')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01ecb0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d01cf70>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d01ecb0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d01d960>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$025scrXo6KJyARDS$ab16a2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 783365)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_non_existant_ta_email(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                team_bulk_upload(
                    retrieve_file_path("f-add-1-team-non-existant-ta-email.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
                error_message = "student_team_to_db() did not correctly return NonExistentTA.error"
                assert False, error_message
            except UserDoesNotExist as e:
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
                delete_all_users_user_courses(result["course_id"])
                assert True
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamBulkUpload.py:38: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:18,786 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$025scrXo6KJyARDS$ab16a2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 783365)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$025scrXo6KJyARDS$ab16a2366f5d413da0a410b48cacc59f8c5f9f57df05338c198506313970be96', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 18, 783365)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
_ test_should_fail_with_suspected_misformatting_error_given_misformatted_ta_email _

self = <sqlalchemy.engine.base.Connection object at 0x12d4e64a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d4e65f0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d4e68c0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d4e65f0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d4e68c0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...f7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.114468')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d4e68c0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...f7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.114468')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d4e42b0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...f7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.114468')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d4e42b0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d4e4a60>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d4e42b0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d4e4880>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_suspected_misformatting_error_given_misformatted_ta_email(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamBulkUpload.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5055085440)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d4e7e80>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cbf4580>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cbf4580>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cbf4580>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cbf4580>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cbf4580>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cbf4580>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d4e7e80>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d4e7e80>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12d4e6fe0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d4e7e80>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d4e4df0>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d4e4df0>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d6d4cf0>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d4e4df0>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d4e4df0>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d6d5620>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d4e64a0>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12d4e64a0>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d4e64a0>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d4e64a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d3a6b60>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d4e65f0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d4e64a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d4e65f0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d4e64a0>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12d4e68c0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d4e65f0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d4e64a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d4e65f0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d4e68c0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d4e65f0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d4e68c0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...f7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.114468')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d4e68c0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...f7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.114468')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d4e42b0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...f7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.114468')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d4e42b0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d4e4a60>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d4e42b0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d4e4880>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$oTACENDwHduMq64z$29a9af7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 114468)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_suspected_misformatting_error_given_misformatted_ta_email(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                team_bulk_upload(
                    retrieve_file_path("f-add-3-people-misformatted-ta-email.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
                error_message = "student_team_to_db() did not correctly return SuspectedMisformatting.error"
                assert False, error_message
            except SuspectedMisformatting as e:
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
                delete_all_users_user_courses(result["course_id"])
                assert True
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamBulkUpload.py:61: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:19,118 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$oTACENDwHduMq64z$29a9af7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 114468)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$oTACENDwHduMq64z$29a9af7892864692a1bd273558075c6df80954a1caf388defe68bff170a58448', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 114468)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
___________________ test_should_fail_with_empty_team_members ___________________

self = <sqlalchemy.engine.base.Connection object at 0x12cc1da20>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cc1d000>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12cc1d480>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cc1d000>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cc1d480>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...57335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.483723')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cc1d480>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...57335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.483723')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cc1ec80>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...57335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.483723')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cc1ec80>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12cc1feb0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cc1ec80>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12cc1d180>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_empty_team_members(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamBulkUpload.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5045876624)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cc1dcf0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d26f240>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d26f240>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d26f240>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d26f240>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d26f240>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d26f240>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cc1dcf0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cc1dcf0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12cc1cd90>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cc1dcf0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cc1cf10>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cc1cf10>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d803760>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cc1cf10>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cc1cf10>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d8037d0>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cc1da20>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12cc1da20>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cc1da20>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cc1da20>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d669ea0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cc1d000>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cc1da20>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cc1d000>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cc1da20>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12cc1d480>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cc1d000>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cc1da20>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cc1d000>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12cc1d480>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cc1d000>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cc1d480>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...57335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.483723')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cc1d480>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...57335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.483723')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cc1ec80>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...57335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.483723')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cc1ec80>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12cc1feb0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cc1ec80>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12cc1d180>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$TZcNF0s60sPHuPqa$9b81657335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 483723)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_empty_team_members(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                res = team_bulk_upload(
                    retrieve_file_path("f-no-students-in-team.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
                error_message = "student_team_to_db() did not correctly return EmptyTeamMembers.error"
                assert False, error_message
            except EmptyTeamMembers as e:
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
                delete_all_users_user_courses(result["course_id"])
                assert True
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamBulkUpload.py:84: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:19,485 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$TZcNF0s60sPHuPqa$9b81657335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 483723)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$TZcNF0s60sPHuPqa$9b81657335be39e14bc3127eacc7f45bc8704c30934ace586ec9cd4f5d69b879', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 483723)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
______ test_should_fail_with_file_not_found_error_given_non_existent_file ______

self = <sqlalchemy.engine.base.Connection object at 0x12d2d9150>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2db940>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d2db160>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2db940>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d2db160>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.810865')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d2db160>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.810865')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2d8af0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.810865')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2d8af0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d2d81f0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2d8af0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d2d8c40>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_file_not_found_error_given_non_existent_file(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamBulkUpload.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5052937408)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d2d81c0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c802040>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c802040>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c802040>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c802040>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c802040>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c802040>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d2d81c0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d2d81c0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12d2d8520>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d2d81c0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d2dad40>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d2dad40>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d6215b0>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d2dad40>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d2dad40>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d623290>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d2d9150>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12d2d9150>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d2d9150>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d2d9150>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d661f00>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2db940>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d2d9150>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2db940>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d2d9150>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12d2db160>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2db940>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d2d9150>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2db940>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d2db160>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d2db940>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d2db160>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.810865')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d2db160>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.810865')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2d8af0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:19.810865')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2d8af0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d2d81f0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d2d8af0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d2d8c40>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$bT65jsmb7UCfuCs3$24b3e12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 810865)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_fail_with_file_not_found_error_given_non_existent_file(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                try:
                    team_bulk_upload(
                        retrieve_file_path("NonExistentFile.csv"),
                        result["admin_id"],
                        result["course_id"]
                    )
                    assert False, "unreachable"
    
                except Exception as e:
                    assert isinstance(e, FileNotFoundError)
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should not assign a test team to a test course!"
                assert teams.__len__() == 0, error_message
    
                delete_one_admin_ta_student_course(result)
                delete_all_users_user_courses(result["course_id"])
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamBulkUpload.py:113: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:19,814 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$bT65jsmb7UCfuCs3$24b3e12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 810865)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$bT65jsmb7UCfuCs3$24b3e12d03195ac5543c4bf924cf474caf09713ebb15e7a9e5e4d4ed4dd0e11a', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 19, 810865)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
_____________________ test_should_pass_when_given_one_team _____________________

self = <sqlalchemy.engine.base.Connection object at 0x10fa38790>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fa39d20>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10fa38f70>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fa39d20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fa38f70>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.181987')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fa38f70>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.181987')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fa3ae90>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.181987')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fa3ae90>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10fa3a080>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fa3ae90>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10fa381c0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_pass_when_given_one_team(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamBulkUpload.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 4557355952)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fa39300>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fd87dc0>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fd87dc0>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fd87dc0>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fd87dc0>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fd87dc0>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fd87dc0>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fa39300>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fa39300>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x10fa38760>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x10fa39300>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fa3ac80>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fa3ac80>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d65fbc0>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fa3ac80>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x10fa3ac80>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d65f680>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fa38790>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x10fa38790>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fa38790>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fa38790>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d640dc0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fa39d20>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fa38790>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fa39d20>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fa38790>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x10fa38f70>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fa39d20>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x10fa38790>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fa39d20>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x10fa38f70>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x10fa39d20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fa38f70>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.181987')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x10fa38f70>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.181987')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fa3ae90>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.181987')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fa3ae90>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x10fa3a080>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x10fa3ae90>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x10fa381c0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$E1s7EqTZdy3CESBf$a3c4d8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 181987)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_pass_when_given_one_team(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                team_bulk_upload(
                    retrieve_file_path("s-insert-1-team-1-ta.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should assign a test team to a test course!"
                assert teams.__len__() == 1, error_message
    
                user = get_user_by_email("teststudent1@gmail.com")
                error_message = "team_csv_to_db() should assign a test team to a test course!"
                assert user.first_name == "fname1", error_message
    
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
                delete_all_users_user_courses(result["course_id"])
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamBulkUpload.py:142: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:20,185 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$E1s7EqTZdy3CESBf$a3c4d8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 181987)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$E1s7EqTZdy3CESBf$a3c4d8debcbbc79d886a2361ae384b1efe22db5a732c11297e165fc09b712051', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 181987)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
_________________ test_should_pass_when_given_two_teams_one_ta _________________

self = <sqlalchemy.engine.base.Connection object at 0x12cfad2a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cfaf790>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12cfacbe0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cfaf790>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cfacbe0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.515752')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cfacbe0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.515752')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cfadc30>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...8c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.515752')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cfadc30>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12cfae4a0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cfadc30>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12cfafa60>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_pass_when_given_two_teams_one_ta(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamBulkUpload.py:151: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5049613328)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cfaccd0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d599c80>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d599c80>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d599c80>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d599c80>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d599c80>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d599c80>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cfaccd0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cfaccd0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12cfac280>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cfaccd0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cfaf280>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cfaf280>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d6dde70>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cfaf280>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cfaf280>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d6dd4d0>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cfad2a0>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12cfad2a0>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cfad2a0>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cfad2a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d649f00>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cfaf790>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cfad2a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cfaf790>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cfad2a0>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12cfacbe0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cfaf790>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cfad2a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cfaf790>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12cfacbe0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cfaf790>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cfacbe0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.515752')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cfacbe0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.515752')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cfadc30>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...8c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.515752')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cfadc30>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12cfae4a0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cfadc30>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12cfafa60>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$1MR4zthuvKzNZjP1$ad7888c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 515752)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_pass_when_given_two_teams_one_ta(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                team_bulk_upload(
                    retrieve_file_path("s-insert-2-teams-1-ta.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should assign a test team to a test course!"
                assert teams.__len__() == 2, error_message
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
                delete_all_users_user_courses(result["course_id"])
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamBulkUpload.py:167: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:20,519 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$1MR4zthuvKzNZjP1$ad7888c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 515752)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$1MR4zthuvKzNZjP1$ad7888c9347797fa0a3215c059ed5a43a2922cd68b042742603b29963b04dd83', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 515752)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
________________ test_should_pass_when_given_three_teams_one_ta ________________

self = <sqlalchemy.engine.base.Connection object at 0x12d356140>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d354b50>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d354a90>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d354b50>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d354a90>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.905218')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d354a90>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.905218')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d356e60>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.905218')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d356e60>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d356170>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d356e60>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d355c90>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_pass_when_given_three_teams_one_ta(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamBulkUpload.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5053443008)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d356bf0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fb43bc0>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fb43bc0>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fb43bc0>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fb43bc0>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fb43bc0>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fb43bc0>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d356bf0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d356bf0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12d356b90>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d356bf0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d356c20>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d356c20>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d8faa40>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d356c20>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d356c20>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d8fab20>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d356140>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12d356140>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d356140>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d356140>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d67cb80>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d354b50>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d356140>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d354b50>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d356140>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12d354a90>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d354b50>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d356140>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d354b50>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d354a90>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d354b50>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d354a90>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.905218')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d354a90>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.905218')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d356e60>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:20.905218')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d356e60>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d356170>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d356e60>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d355c90>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$lzyFuc1xrOszOO1g$fb5ff8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 905218)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_pass_when_given_three_teams_one_ta(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                team_bulk_upload(
                    retrieve_file_path("s-insert-3-teams-1-ta.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should assign a test team to a test course!"
                assert teams.__len__() == 3, error_message
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
                delete_all_users_user_courses(result["course_id"])
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamBulkUpload.py:192: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:20,908 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$lzyFuc1xrOszOO1g$fb5ff8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 905218)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$lzyFuc1xrOszOO1g$fb5ff8798de5d07cd571a94912968abe176ab086154b79c1826dfcae30f159fa', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 20, 905218)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
__________________ test_should_pass_when_given_2_teams_2_tas ___________________

self = <sqlalchemy.engine.base.Connection object at 0x12db3c1f0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12db3d030>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12db3ef20>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12db3d030>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12db3ef20>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.246918')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12db3ef20>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.246918')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12db3f1f0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.246918')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12db3f1f0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12db3e380>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12db3f1f0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12db3e950>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_should_pass_when_given_2_teams_2_tas(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_two_admin_two_ta_student_course()

Functions/test_files/test_teamBulkUpload.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_two_admin_two_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:175: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5061731680)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12db3d2a0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cf3f780>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cf3f780>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cf3f780>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cf3f780>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cf3f780>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cf3f780>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12db3d2a0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12db3d2a0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12db3c070>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12db3d2a0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12db3dd50>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12db3dd50>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12cbbeb90>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12db3dd50>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12db3dd50>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12cbbdd20>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12db3c1f0>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12db3c1f0>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12db3c1f0>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12db3c1f0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12cb27c40>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12db3d030>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12db3c1f0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12db3d030>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12db3c1f0>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12db3ef20>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12db3d030>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12db3c1f0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12db3d030>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12db3ef20>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12db3d030>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12db3ef20>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.246918')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12db3ef20>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.246918')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12db3f1f0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.246918')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12db3f1f0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12db3e380>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12db3f1f0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12db3e950>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$Pp8MryYK1nLoCgXt$79219c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 246918)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_should_pass_when_given_2_teams_2_tas(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_two_admin_two_ta_student_course()
                team_bulk_upload(
                    retrieve_file_path("s-insert-2-teams-2-tas.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should assign a test team to a test course!"
                assert teams.__len__() == 2, error_message
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
                delete_all_users_user_courses(result["course_id"])
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamBulkUpload.py:217: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:21,249 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$Pp8MryYK1nLoCgXt$79219c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 246918)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$Pp8MryYK1nLoCgXt$79219c3c41044fd11756c56e18107619c7f7c3a6f88c6845ad92ecf552bb4a4b', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 246918)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
____________________ test_valid_file_w_tas_records_all_data ____________________

self = <sqlalchemy.engine.base.Connection object at 0x12c9d3c40>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9d2170>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12c9d29e0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9d2170>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9d29e0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.617497')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9d29e0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.617497')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9d1a80>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.617497')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9d1a80>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12c9d3be0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9d1a80>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12c9d3d30>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_valid_file_w_tas_records_all_data(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamImport.py:26: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5043467312)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9d34f0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fdef800>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fdef800>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fdef800>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fdef800>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fdef800>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fdef800>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9d34f0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9d34f0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12c9d1ab0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9d34f0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9d1f00>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9d1f00>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12cb2ad50>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9d1f00>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9d1f00>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12cb2a650>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9d3c40>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12c9d3c40>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9d3c40>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9d3c40>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12cb321a0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9d2170>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9d3c40>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9d2170>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9d3c40>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12c9d29e0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9d2170>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9d3c40>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9d2170>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12c9d29e0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9d2170>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9d29e0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.617497')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9d29e0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.617497')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9d1a80>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.617497')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9d1a80>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12c9d3be0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9d1a80>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12c9d3d30>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$CaY78XpD48zjjMH0$fa06e30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 617497)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_valid_file_w_tas_records_all_data(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                message = teamImport.team_csv_to_db(
                    retrieve_file_path("oneTeamTAStudent.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
    
                error_message = "team_csv_to_db() did not return the expected success message!"
                assert message == "Upload successful!", error_message
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() did not correctly create the valid test team!"
                assert teams.__len__() == 1, error_message
    
                teams = get_team_by_course_id(result["course_id"])
    
                team_users = get_team_users_by_team_id(teams[0].team_id)
    
                error_message = "teams_csv_to_db() did not correctly assign the test student to the test team!"
                assert team_users.__len__() == 2, error_message
    
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:52: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:21,620 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$CaY78XpD48zjjMH0$fa06e30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 617497)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$CaY78XpD48zjjMH0$fa06e30b6287bf5f5aa289a58421d2ec89ddf6d51eb37bbb4d3af0a881aece84', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 617497)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
___________________ test_valid_file_wo_tas_records_all_data ____________________

self = <sqlalchemy.engine.base.Connection object at 0x12dbb8940>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12dbba0e0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12dbba1a0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12dbba0e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12dbba1a0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.950624')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12dbba1a0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.950624')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12dbb9480>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.950624')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12dbb9480>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12dbb89a0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12dbb9480>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12dbb86a0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_valid_file_wo_tas_records_all_data(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course(False)

Functions/test_files/test_teamImport.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = False, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5062234256)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12dbb9030>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ffa51c0>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ffa51c0>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ffa51c0>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ffa51c0>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ffa51c0>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10ffa51c0>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12dbb9030>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12dbb9030>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12dbb9600>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12dbb9030>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12dbb9270>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12dbb9270>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12cbb7760>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12dbb9270>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12dbb9270>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12cbb7ae0>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12dbb8940>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12dbb8940>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12dbb8940>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12dbb8940>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12cb5ec80>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12dbba0e0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12dbb8940>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12dbba0e0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12dbb8940>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12dbba1a0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12dbba0e0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12dbb8940>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12dbba0e0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12dbba1a0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12dbba0e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12dbba1a0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.950624')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12dbba1a0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.950624')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12dbb9480>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:21.950624')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12dbb9480>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12dbb89a0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12dbb9480>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12dbb86a0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$9FADx1vPQdPxf6OJ$c44bd430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 950624)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_valid_file_wo_tas_records_all_data(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course(False)
                message = teamImport.team_csv_to_db(
                    retrieve_file_path("oneTeamStudent.csv"),
                    result["admin_id"],
                    result["course_id"]
                )
    
                error_message = "team_csv_to_db() did not return the expected success message!"
                assert message == "Upload successful!", error_message
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() did not correctly assign the test team to the test course!"
                assert teams.__len__() == 1, error_message
    
                teams = get_team_by_course_id(result["course_id"])
                team_users = get_team_users_by_team_id(teams[0].team_id)
    
                error_message = "team_csv_to_db() did not correctly assign the test student to the test team!"
                assert team_users.__len__() == 1, error_message
    
                delete_all_teams_team_members(result["course_id"])
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:95: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:21,953 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$9FADx1vPQdPxf6OJ$c44bd430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 950624)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$9FADx1vPQdPxf6OJ$c44bd430b328f4974e0a3403351ca07fc246e16cbd4a7e29cd49ff7507d7230e', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 21, 950624)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
__________________________ test_wrong_file_type_error __________________________

self = <sqlalchemy.engine.base.Connection object at 0x12c9b1060>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9b20b0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12c9b0340>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9b20b0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9b0340>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.282794')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9b0340>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.282794')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9b3370>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...c71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.282794')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9b3370>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12c9b1360>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9b3370>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12c9b3b80>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_wrong_file_type_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamImport.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5043336768)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9b3760>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d31f300>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d31f300>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d31f300>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d31f300>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d31f300>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d31f300>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9b3760>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9b3760>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12c9b1cc0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9b3760>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9b3040>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9b3040>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12d5a5e70>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9b3040>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9b3040>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12d5a5230>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9b1060>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12c9b1060>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9b1060>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9b1060>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12d61e980>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9b20b0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9b1060>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9b20b0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9b1060>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12c9b0340>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9b20b0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9b1060>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9b20b0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12c9b0340>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9b20b0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9b0340>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.282794')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9b0340>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...c71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.282794')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9b3370>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...c71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.282794')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9b3370>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12c9b1360>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9b3370>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12c9b3b80>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$UqqrlLmzOOvD9H2j$c29edc71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 282794)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_wrong_file_type_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                try:
                    message = teamImport.team_csv_to_db(
                        retrieve_file_path(
                            "WrongFileType.pdf"
                        ),
                        result["admin_id"],
                        result["course_id"]
                    )
    
                except Exception as e:
                    assert isinstance(e, WrongExtension)
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should not assign a test team to a test course!"
                assert teams.__len__() == 0, error_message
    
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:129: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:22,286 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$UqqrlLmzOOvD9H2j$c29edc71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 282794)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$UqqrlLmzOOvD9H2j$c29edc71b121ad6eac156b051a087aec06ff4f4efff322244d5d42d64efc3728', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 282794)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
__________________________ test_file_not_found_error ___________________________

self = <sqlalchemy.engine.base.Connection object at 0x12d8348e0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d835750>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d834070>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d835750>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d834070>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.654001')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d834070>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.654001')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d835cc0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.654001')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d835cc0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d834c40>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d835cc0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d837220>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_file_not_found_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamImport.py:142: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5058559520)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d8369b0>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cdac940>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cdac940>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cdac940>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cdac940>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cdac940>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12cdac940>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d8369b0>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d8369b0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12d835360>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d8369b0>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d836b60>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d836b60>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x10fd349e0>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d836b60>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d836b60>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x10fd37c30>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d8348e0>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12d8348e0>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d8348e0>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d8348e0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12cbdda20>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d835750>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d8348e0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d835750>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d8348e0>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12d834070>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d835750>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d8348e0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d835750>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d834070>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d835750>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d834070>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.654001')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d834070>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.654001')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d835cc0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.654001')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d835cc0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d834c40>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d835cc0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d837220>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$AHQI6v9VZ5TYJCiK$8b1da1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 654001)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_file_not_found_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                try:
                    message = teamImport.team_csv_to_db(
                        retrieve_file_path(
                            "NonExistentFile.csv"
                        ),
                        result["admin_id"],
                        result["course_id"]
                    )
    
                except Exception as e:
                    assert isinstance(e, FileNotFoundError)
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should not assign a test team to a test course!"
                assert teams.__len__() == 0, error_message
    
                delete_one_admin_ta_student_course(result)
    
            except:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:163: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:22,657 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$AHQI6v9VZ5TYJCiK$8b1da1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 654001)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$AHQI6v9VZ5TYJCiK$8b1da1859f9bffab07fd376fbdbe65bc1094b2c881b055913d05dad82c365ffb', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 654001)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
______________________ test_misformatting_TA_email_error _______________________

self = <sqlalchemy.engine.base.Connection object at 0x12c9a9990>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9a87f0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12c9ab3a0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9a87f0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9ab3a0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.992583')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9ab3a0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.992583')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9a8520>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.992583')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9a8520>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12c9abd90>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9a8520>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12c9a99f0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_misformatting_TA_email_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamImport.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5043296848)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9ab310>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d3f7480>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d3f7480>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d3f7480>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d3f7480>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d3f7480>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12d3f7480>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9ab310>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9ab310>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12c9a8eb0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12c9ab310>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9ab6d0>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9ab6d0>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x10fdfd070>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9ab6d0>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12c9ab6d0>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x10fdfc4a0>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9a9990>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12c9a9990>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9a9990>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9a9990>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12cbd0be0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9a87f0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9a9990>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9a87f0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9a9990>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12c9ab3a0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9a87f0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12c9a9990>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9a87f0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12c9ab3a0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12c9a87f0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9ab3a0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.992583')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12c9ab3a0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.992583')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9a8520>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:22.992583')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9a8520>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12c9abd90>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12c9a8520>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12c9a99f0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$EWmC4hhszb5ssP3s$a2dff94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 992583)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_misformatting_TA_email_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                try:
                    message = teamImport.team_csv_to_db(
                        retrieve_file_path(
                            "oneTeamMisformattedTAStudent.csv"
                        ),
                        result["admin_id"],
                        result["course_id"]
                    )
    
                except Exception as e:
                    assert isinstance(e, SuspectedMisformatting)
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should not assign a test team to a test course!"
                assert teams.__len__() == 0, error_message
    
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:200: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:22,996 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$EWmC4hhszb5ssP3s$a2dff94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 992583)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$EWmC4hhszb5ssP3s$a2dff94e958afe9df903fcf635114f91749d6a1023817f9a76b484c03196a3e0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 22, 992583)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
____________________ test_misformatting_student_email_error ____________________

self = <sqlalchemy.engine.base.Connection object at 0x12d82d0c0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d82d600>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d82d2a0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d82d600>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d82d2a0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...cc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.360401')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d82d2a0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...cc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.360401')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d82f1f0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...cc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.360401')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d82f1f0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d82fd90>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d82f1f0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d82efb0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_misformatting_student_email_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course(False)

Functions/test_files/test_teamImport.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = False, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5058523824)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d82e170>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c91f000>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c91f000>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c91f000>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c91f000>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c91f000>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c91f000>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d82e170>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d82e170>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12d82c760>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12d82e170>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d82ece0>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d82ece0>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x10fd7a880>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d82ece0>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12d82ece0>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x10fd7aff0>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d82d0c0>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12d82d0c0>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d82d0c0>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d82d0c0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x10fdad9c0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d82d600>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d82d0c0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d82d600>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d82d0c0>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12d82d2a0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d82d600>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12d82d0c0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d82d600>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12d82d2a0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12d82d600>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d82d2a0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...cc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.360401')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12d82d2a0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...cc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.360401')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d82f1f0>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...cc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.360401')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d82f1f0>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12d82fd90>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12d82f1f0>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12d82efb0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$EvFFn1KvPB5S2Ltu$96c8ccc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 23, 360401)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_misformatting_student_email_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course(False)
                try:
                    message = teamImport.team_csv_to_db(
                        retrieve_file_path(
                            "oneTeamMisformattedStudent.csv"
                        ),
                        result["admin_id"],
                        result["course_id"]
                    )
    
                except Exception as e:
                    assert isinstance(e, SuspectedMisformatting)
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should not assign a test team to a test course!"
                assert teams.__len__() == 0, error_message
    
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:237: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:23,363 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$EvFFn1KvPB5S2Ltu$96c8ccc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 23, 360401)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$EvFFn1KvPB5S2Ltu$96c8ccc4f6fbc1eec6f541de98fd87db61ecbc4bcf4486d2861ac3c2d6875c39', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 23, 360401)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
________________________ test_users_do_not_exist_error _________________________

self = <sqlalchemy.engine.base.Connection object at 0x12cee2200>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cee2e30>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12cee33a0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cee2e30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cee33a0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.688315')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cee33a0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.688315')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cee1060>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.688315')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cee1060>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12cee2f80>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cee1060>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12cee0190>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_users_do_not_exist_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course()

Functions/test_files/test_teamImport.py:253: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5048778128)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cee3730>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fbc2bc0>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fbc2bc0>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fbc2bc0>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fbc2bc0>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fbc2bc0>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x10fbc2bc0>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cee3730>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cee3730>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12cee1cc0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cee3730>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cee3070>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cee3070>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12c8b7d80>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cee3070>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cee3070>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12c8b7ae0>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cee2200>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12cee2200>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cee2200>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cee2200>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12c80bd00>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cee2e30>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cee2200>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cee2e30>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cee2200>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12cee33a0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cee2e30>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cee2200>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cee2e30>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12cee33a0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cee2e30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cee33a0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.688315')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cee33a0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.688315')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cee1060>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:23.688315')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cee1060>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12cee2f80>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cee1060>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12cee0190>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$kO8HJvXZpRLBrgnH$4de51ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 23, 688315)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_users_do_not_exist_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course()
                try:
                    message = teamImport.team_csv_to_db(
                        retrieve_file_path(
                            "oneTeamNonExistingTAStudent.csv"
                        ),
                        result["admin_id"],
                        result["course_id"]
                    )
    
                except Exception as e:
                    assert isinstance(e, UserDoesNotExist)
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should not assign a test team to a test course!"
                assert teams.__len__() == 0, error_message
    
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:274: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:23,691 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$kO8HJvXZpRLBrgnH$4de51ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 23, 688315)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$kO8HJvXZpRLBrgnH$4de51ccbba5f4cf48c8a6a91d65c4e0edaebd0df02b185ea780c880ed6906a78', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 23, 688315)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
_________________________ test_ta_not_yet_added_error __________________________

self = <sqlalchemy.engine.base.Connection object at 0x12cca40a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cca7bb0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12cca4370>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cca7bb0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cca4370>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.054562')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cca4370>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.054562')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cca7220>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.054562')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cca7220>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12cca50c0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cca7220>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12cca52a0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_ta_not_yet_added_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course(True, True)

Functions/test_files/test_teamImport.py:292: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = True, unenroll_student = False

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5046422928)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cca6500>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c9c46c0>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c9c46c0>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c9c46c0>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c9c46c0>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c9c46c0>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c9c46c0>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cca6500>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cca6500>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12cca48b0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12cca6500>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cca5c90>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cca5c90>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x12cb9d000>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cca5c90>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12cca5c90>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x12cb9cb30>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cca40a0>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12cca40a0>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cca40a0>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cca40a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12c899840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cca7bb0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cca40a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cca7bb0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cca40a0>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12cca4370>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cca7bb0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12cca40a0>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cca7bb0>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12cca4370>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12cca7bb0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cca4370>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.054562')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12cca4370>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.054562')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cca7220>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.054562')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cca7220>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12cca50c0>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12cca7220>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12cca52a0>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$0aavsJGm4GpNDdkS$87afb0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 24, 54562)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_ta_not_yet_added_error(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course(True, True)
    
                try:
                    message = teamImport.team_csv_to_db(
                        retrieve_file_path(
                            "oneTeamTAStudent.csv"
                        ),
                        result["admin_id"],
                        result["course_id"]
                    )
                    assert False
                except Exception as e:
                    assert isinstance(e, TANotYetAddedToCourse)
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should not assign a test team to a test course!"
                assert teams.__len__() == 0, error_message
    
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:314: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:24,066 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$0aavsJGm4GpNDdkS$87afb0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 24, 54562)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$0aavsJGm4GpNDdkS$87afb0698d96f2637450f06e1a7f0a98317f9f1372294a88ffd2cbe006505ca6', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 24, 54562)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
___________________ test_student_not_enrolled_in_this_course ___________________

self = <sqlalchemy.engine.base.Connection object at 0x12daa3a30>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12daa3a00>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12daa09d0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12daa3a00>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12daa09d0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.397655')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12daa09d0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.397655')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12daa1840>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.397655')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12daa1840>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12daa3850>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12daa1840>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12daa3f70>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       pymysql.err.IntegrityError: (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

The above exception was the direct cause of the following exception:

flask_app_mock = <Flask 'core'>

    def test_student_not_enrolled_in_this_course(flask_app_mock):
        with flask_app_mock.app_context():
            try:
>               result = create_one_admin_ta_student_course(True, False, True)

Functions/test_files/test_teamImport.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

use_tas = True, unenroll_ta = False, unenroll_student = True

    def create_one_admin_ta_student_course(use_tas=True, unenroll_ta=False, unenroll_student=False):
        teacher = template_user
        teacher["first_name"] = "Test Teacher"
        teacher["last_name"] = "1"
        teacher["email"] = f"testteacher@gmail.com"
        teacher["owner_id"] = 1
>       new_teacher = create_user(teacher)

Functions/test_files/PopulationFunctions.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
            return f(*args, *kwargs)
    
        except BaseException as e:
            logger.error(f"{e.__traceback__.tb_frame.f_code.co_filename} { e.__traceback__.tb_lineno} Error Type: {type(e).__name__} Message: {e}")
>           raise e

models/utility.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ({'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'last_name': '1', ...},)
kwargs = {}

    def wrapper(*args, **kwargs):
        try:
>           return f(*args, *kwargs)

models/utility.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

user_data = <User (transient 5061085120)>, owner_email = None

    @error_log
    def create_user(user_data, owner_email=None):
        if "password" in user_data:
            password = user_data["password"]
            has_set_password = True # for demo users, avoid requirement to choose new password
        else:
            password = generate_random_password(6)
            send_new_user_email(user_data["email"], password)
    
            has_set_password = False
    
        password_hash = generate_password_hash(password)
        last_update = datetime.now()
    
        user_data = User(
            first_name=user_data["first_name"],
            last_name=user_data["last_name"],
            email=user_data["email"].lower().strip(),
            password=password_hash,
            lms_id=user_data["lms_id"],
            consent=user_data["consent"],
            owner_id=user_data["owner_id"],
            is_admin="role_id" in user_data.keys() and user_data["role_id"] in [1,2,3],
            has_set_password=has_set_password,
            reset_code=None,
            last_update=last_update,
        )
    
        db.session.add(user_data)
    
>       db.session.commit()

models/user.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.scoping.scoped_session object at 0x104d21120>

    def commit(self) -> None:
        r"""Flush pending changes and commit the current transaction.
    
        .. container:: class_bases
    
            Proxied for the :class:`_orm.Session` class on
            behalf of the :class:`_orm.scoping.scoped_session` class.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
    
        """  # noqa: E501
    
>       return self._proxied.commit()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/scoping.py:553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12daa2290>

    def commit(self) -> None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
>       trans.commit(_to_root=True)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1906: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c970900>
_to_root = True

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction.commit at 0x10493fb50>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c970900>
arg = (), kw = {'_to_root': True}
current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <_StateChangeStates.ANY: 1>, existing_fn = None
expect_state = <SessionTransactionState.CLOSED: 5>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c970900>
_to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -> None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
>               self._prepare_impl()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c970900>

>   ???

<string>:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function SessionTransaction._prepare_impl at 0x10493f9a0>
self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c970900>
arg = (), kw = {}, current_state = <SessionTransactionState.ACTIVE: 1>
next_state = <SessionTransactionState.PREPARED: 2>
existing_fn = <function SessionTransaction.commit at 0x10493fb50>
expect_state = <SessionTransactionState.PREPARED: 2>

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -> Any:
    
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}"
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}"
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
>           ret_value = fn(self, *arg, **kw)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.SessionTransaction object at 0x12c970900>

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -> None:
    
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
>               self.session.flush()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12daa2290>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
>           self._flush(objects)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12daa2290>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
>           with util.safe_reraise():

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x12daa18a0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x12daa2290>, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -> None:
    
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
>               flush_context.execute()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12daa0160>

    def execute(self) -> None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
>               rec.execute(self)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = SaveUpdateAll(Mapper[User(User)])
uow = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12daa0160>

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
>       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
states = <generator object UOWTransaction.states_for_mapper_hierarchy at 0x10fdbc200>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12daa0160>
single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
>           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

base_mapper = <Mapper at 0x104ec6200; User>
uowtransaction = <sqlalchemy.orm.unitofwork.UOWTransaction object at 0x12daa0160>
mapper = <Mapper at 0x104ec6200; User>
table = Table('User', MetaData(), Column('user_id', Integer(), table=<User>, primary_key=True, nullable=False), Column('first_...', Boolean(), table=<User>, nullable=False), Column('last_update', DateTime(timezone=True), table=<User>), schema=None)
insert = <generator object _collect_insert_commands at 0x10fdbc190>

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
    
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
    
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                result.returned_defaults
                                if not result.context.executemany
                                else None,
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    not hasvalue and len(records) > 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
                    result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )
    
                    if use_orm_insert_stmt is not None:
                        if return_result is None:
                            return_result = result
                        else:
                            return_result = return_result.splice_vertically(result)
    
                    if bookkeeping:
                        for (
                            (
                                state,
                                state_dict,
                                params,
                                mapper_rec,
                                conn,
                                value_params,
                                has_all_pks,
                                has_all_defaults,
                            ),
                            last_inserted_params,
                            inserted_primary_key,
                            returned_defaults,
                        ) in zip_longest(
                            records,
                            result.context.compiled_parameters,
                            result.inserted_primary_key_rows,
                            result.returned_defaults_rows or (),
                        ):
                            if inserted_primary_key is None:
                                # this is a real problem and means that we didn't
                                # get back as many PK rows.  we can't continue
                                # since this indicates PK rows were missing, which
                                # means we likely mis-populated records starting
                                # at that point with incorrectly matched PK
                                # values.
                                raise orm_exc.FlushError(
                                    "Multi-row INSERT statement for %s did not "
                                    "produce "
                                    "the correct number of INSERTed rows for "
                                    "RETURNING.  Ensure there are no triggers or "
                                    "special driver issues preventing INSERT from "
                                    "functioning properly." % mapper_rec
                                )
    
                            for pk, col in zip(
                                inserted_primary_key,
                                mapper._pks_by_table[table],
                            ):
                                prop = mapper_rec._columntoproperty[col]
                                if state_dict.get(prop.key) is None:
                                    state_dict[prop.key] = pk
    
                            if state:
                                _postfetch(
                                    mapper_rec,
                                    uowtransaction,
                                    table,
                                    state,
                                    state_dict,
                                    result,
                                    last_inserted_params,
                                    value_params,
                                    False,
                                    returned_defaults,
                                )
                            else:
                                _postfetch_bulk_save(mapper_rec, state_dict, table)
                else:
                    assert not returning_is_required_anyway
    
                    for (
                        state,
                        state_dict,
                        params,
                        mapper_rec,
                        connection,
                        value_params,
                        has_all_pks,
                        has_all_defaults,
                    ) in records:
                        if value_params:
                            result = connection.execute(
                                statement.values(value_params),
                                params,
                                execution_options=execution_options,
                            )
                        else:
>                           result = connection.execute(
                                statement,
                                params,
                                execution_options=execution_options,
                            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12daa3a30>
statement = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
connection = <sqlalchemy.engine.base.Connection object at 0x12daa3a30>
distilled_params = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = {'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12daa3a30>
elem = <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>
distilled_parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12daa3a30>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb'>>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': True, ...}]
execution_options = immutabledict({'compiled_cache': <sqlalchemy.util._collections.LRUCache object at 0x10f838b30>})
args = (<sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>, [{'consent': None, 'email': 'testtea..., 'first_name': 'Test Teacher', 'has_set_password': True, ...}], <sqlalchemy.sql.dml.Insert object at 0x10f87afb0>, [])
kw = {'cache_hit': <CacheStats.CACHE_HIT: 0>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x12c80be80>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12daa3a00>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(
                dialect,
                context,
            )
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12daa3a30>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12daa3a00>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12daa3a30>
e = IntegrityError(1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
cursor = <pymysql.cursors.Cursor object at 0x12daa09d0>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12daa3a00>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x12daa3a30>
dialect = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12daa3a00>
statement = <sqlalchemy.dialects.mysql.mysqldb.MySQLCompiler_mysqldb object at 0x10f85bee0>
parameters = [{'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
    
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.mysql.pymysql.MySQLDialect_pymysql object at 0x104d21840>
cursor = <pymysql.cursors.Cursor object at 0x12daa09d0>
statement = 'INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...assword)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)'
parameters = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}
context = <sqlalchemy.dialects.mysql.mysqldb.MySQLExecutionContext_mysqldb object at 0x12daa3a00>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sqlalchemy/engine/default.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12daa09d0>
query = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.397655')"
args = {'consent': None, 'email': 'testteacher@gmail.com', 'first_name': 'Test Teacher', 'has_set_password': 1, ...}

    def execute(self, query, args=None):
        """Execute a query.
    
        :param query: Query to execute.
        :type query: str
    
        :param args: Parameters used with query. (optional)
        :type args: tuple, list or dict
    
        :return: Number of affected rows.
        :rtype: int
    
        If args is a list or tuple, %s can be used as a placeholder in the query.
        If args is a dict, %(name)s can be used as a placeholder in the query.
        """
        while self.nextset():
            pass
    
        query = self.mogrify(query, args)
    
>       result = self._query(query)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.cursors.Cursor object at 0x12daa09d0>
q = "INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, ...986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.397655')"

    def _query(self, q):
        conn = self._get_db()
        self._clear_result()
>       conn.query(q)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/cursors.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12daa1840>
sql = b"INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code,...986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', NULL, NULL, 1, 1, NULL, 0, '2025-03-04 15:58:24.397655')"
unbuffered = False

    def query(self, sql, unbuffered=False):
        # if DEBUG:
        #     print("DEBUG: sending query:", sql)
        if isinstance(sql, str):
            sql = sql.encode(self.encoding, "surrogateescape")
        self._execute_command(COMMAND.COM_QUERY, sql)
>       self._affected_rows = self._read_query_result(unbuffered=unbuffered)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12daa1840>
unbuffered = False

    def _read_query_result(self, unbuffered=False):
        self._result = None
        if unbuffered:
            try:
                result = MySQLResult(self)
                result.init_unbuffered_query()
            except:
                result.unbuffered_active = False
                result.connection = None
                raise
        else:
            result = MySQLResult(self)
>           result.read()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:779: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.MySQLResult object at 0x12daa3850>

    def read(self):
        try:
>           first_packet = self.connection._read_packet()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:1157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.connections.Connection object at 0x12daa1840>
packet_type = <class 'pymysql.protocol.MysqlPacket'>

    def _read_packet(self, packet_type=MysqlPacket):
        """Read an entire "mysql packet" in its entirety from the network
        and return a MysqlPacket type that represents the results.
    
        :raise OperationalError: If the connection to the MySQL server is lost.
        :raise InternalError: If the packet sequence number is wrong.
        """
        buff = bytearray()
        while True:
            packet_header = self._read_bytes(4)
            # if DEBUG: dump_packet(packet_header)
    
            btrl, btrh, packet_number = struct.unpack("<HBB", packet_header)
            bytes_to_read = btrl + (btrh << 16)
            if packet_number != self._next_seq_id:
                self._force_close()
                if packet_number == 0:
                    # MariaDB sends error packet with seqno==0 when shutdown
                    raise err.OperationalError(
                        CR.CR_SERVER_LOST,
                        "Lost connection to MySQL server during query",
                    )
                raise err.InternalError(
                    "Packet sequence number wrong - got %d expected %d"
                    % (packet_number, self._next_seq_id)
                )
            self._next_seq_id = (self._next_seq_id + 1) % 256
    
            recv_data = self._read_bytes(bytes_to_read)
            if DEBUG:
                dump_packet(recv_data)
            buff += recv_data
            # https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html
            if bytes_to_read == 0xFFFFFF:
                continue
            if bytes_to_read < MAX_PACKET_LEN:
                break
    
        packet = packet_type(bytes(buff), self.encoding)
        if packet.is_error_packet():
            if self._result is not None and self._result.unbuffered_active is True:
                self._result.unbuffered_active = False
>           packet.raise_for_error()

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/connections.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pymysql.protocol.MysqlPacket object at 0x12daa3f70>

    def raise_for_error(self):
        self.rewind()
        self.advance(1)  # field_count == error (we already know that)
        errno = self.read_uint16()
        if DEBUG:
            print("errno =", errno)
>       err.raise_mysql_exception(self._data)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/protocol.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = b"\xff&\x04#23000Duplicate entry 'testteacher@gmail.com' for key 'user.email'"

    def raise_mysql_exception(data):
        errno = struct.unpack("<h", data[1:3])[0]
        errval = data[9:].decode("utf-8", "replace")
        errorclass = error_map.get(errno)
        if errorclass is None:
            errorclass = InternalError if errno < 1000 else OperationalError
>       raise errorclass(errno, errval)
E       sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
E       [SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
E       [parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$Ig7aPpWk5HIQnWKE$ded54986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 24, 397655)}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pymysql/err.py:143: IntegrityError

During handling of the above exception, another exception occurred:

flask_app_mock = <Flask 'core'>

    def test_student_not_enrolled_in_this_course(flask_app_mock):
        with flask_app_mock.app_context():
            try:
                result = create_one_admin_ta_student_course(True, False, True)
                try:
                    message = teamImport.team_csv_to_db(
                        retrieve_file_path(
                            "oneTeamTAStudent.csv"
                        ),
                        result["admin_id"],
                        result["course_id"]
                    )
    
                except Exception as e:
                    assert isinstance(e, StudentNotEnrolledInThisCourse)
    
                teams = get_team_by_course_id(result["course_id"])
    
                error_message = "team_csv_to_db() should not assign a test team to a test course!"
                assert teams.__len__() == 0, error_message
    
                delete_one_admin_ta_student_course(result)
    
            except Exception as e:
>               delete_all_teams_team_members(result["course_id"])
E               UnboundLocalError: local variable 'result' referenced before assignment

Functions/test_files/test_teamImport.py:354: UnboundLocalError
----------------------------- Captured stderr call -----------------------------
2025-03-04 15:58:24,399 - ERROR - /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$Ig7aPpWk5HIQnWKE$ded54986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 24, 397655)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
------------------------------ Captured log call -------------------------------
ERROR    rubricapp_logger:logger.py:126 /Users/sahammond/rubricapp/BackEndFlask/models/utility.py 114 Error Type: IntegrityError Message: (pymysql.err.IntegrityError) (1062, "Duplicate entry 'testteacher@gmail.com' for key 'user.email'")
[SQL: INSERT INTO `User` (first_name, last_name, email, password, lms_id, consent, owner_id, has_set_password, reset_code, is_admin, last_update) VALUES (%(first_name)s, %(last_name)s, %(email)s, %(password)s, %(lms_id)s, %(consent)s, %(owner_id)s, %(has_set_password)s, %(reset_code)s, %(is_admin)s, %(last_update)s)]
[parameters: {'first_name': 'Test Teacher', 'last_name': '1', 'email': 'testteacher@gmail.com', 'password': 'pbkdf2:sha256:260000$Ig7aPpWk5HIQnWKE$ded54986a8bd98dcc23f56c7d89d295977e8088249fe394f36432350c77976b0', 'lms_id': None, 'consent': None, 'owner_id': 1, 'has_set_password': 1, 'reset_code': None, 'is_admin': 0, 'last_update': datetime.datetime(2025, 3, 4, 15, 58, 24, 397655)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
=========================== short test summary info ============================
FAILED Functions/test_files/test_genericImport.py::test_should_fail_with_file_not_found
FAILED Functions/test_files/test_genericImport.py::test_should_fail_with_wrong_extension
FAILED Functions/test_files/test_genericImport.py::test_should_fail_with_not_enough_columns
FAILED Functions/test_files/test_genericImport.py::test_should_fail_with_misformatted_student_email
FAILED Functions/test_files/test_genericImport.py::test_valid_student_with_no_lms_id_in_table
FAILED Functions/test_files/test_genericImport.py::test_valid_student_with_lms_id_in_table
FAILED Functions/test_files/test_genericImport.py::test_valid_ta_with_no_lms_id_in_table
FAILED Functions/test_files/test_genericImport.py::test_valid_ta_with_lms_id_in_table
FAILED Functions/test_files/test_genericImport.py::test_valid_student_and_ta_with_no_lms_id_in_table
FAILED Functions/test_files/test_genericImport.py::test_valid_students_and_tas_with__and_without_lms_id_in_table
FAILED Functions/test_files/test_randAssignTeams.py::test_one_ta_ten_students
FAILED Functions/test_files/test_randAssignTeams.py::test_no_ta_ten_students
FAILED Functions/test_files/test_randAssignTeams.py::test_ten_tas_ten_students
FAILED Functions/test_files/test_randAssignTeams.py::test_TA_true_but_no_TAs_recorded_error
FAILED Functions/test_files/test_randAssignTeams.py::test_no_students_in_course_error
FAILED Functions/test_files/test_teamBulkUpload.py::test_should_fail_with_non_existant_ta_email
FAILED Functions/test_files/test_teamBulkUpload.py::test_should_fail_with_suspected_misformatting_error_given_misformatted_ta_email
FAILED Functions/test_files/test_teamBulkUpload.py::test_should_fail_with_empty_team_members
FAILED Functions/test_files/test_teamBulkUpload.py::test_should_fail_with_file_not_found_error_given_non_existent_file
FAILED Functions/test_files/test_teamBulkUpload.py::test_should_pass_when_given_one_team
FAILED Functions/test_files/test_teamBulkUpload.py::test_should_pass_when_given_two_teams_one_ta
FAILED Functions/test_files/test_teamBulkUpload.py::test_should_pass_when_given_three_teams_one_ta
FAILED Functions/test_files/test_teamBulkUpload.py::test_should_pass_when_given_2_teams_2_tas
FAILED Functions/test_files/test_teamImport.py::test_valid_file_w_tas_records_all_data
FAILED Functions/test_files/test_teamImport.py::test_valid_file_wo_tas_records_all_data
FAILED Functions/test_files/test_teamImport.py::test_wrong_file_type_error - ...
FAILED Functions/test_files/test_teamImport.py::test_file_not_found_error - U...
FAILED Functions/test_files/test_teamImport.py::test_misformatting_TA_email_error
FAILED Functions/test_files/test_teamImport.py::test_misformatting_student_email_error
FAILED Functions/test_files/test_teamImport.py::test_users_do_not_exist_error
FAILED Functions/test_files/test_teamImport.py::test_ta_not_yet_added_error
FAILED Functions/test_files/test_teamImport.py::test_student_not_enrolled_in_this_course
======================== 32 failed, 1 passed in 21.59s =========================
